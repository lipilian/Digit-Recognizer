{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"4d38db05-fad0-468c-9000-20caf5465eca","_uuid":"ea9eba414f2f0f1e63ef564dc0ee708c753ff51f"},"source":["<a id=\"4\"></a> <br>\n","### Artificial Neural Network (ANN)\n","- Logistic regression is good at classification but when complexity(non linearity) increases, the accuracy of model decreases.\n","- Therefore, we need to increase complexity of model.\n","- In order to increase complexity of model, we need to add more non linear functions as hidden layer. \n","- I am saying again that if you do not know what is artificial neural network check my deep learning tutorial because I will not explain neural network detailed here, only explain pytorch.\n","- Artificial Neural Network tutorial: https://www.kaggle.com/kanncaa1/deep-learning-tutorial-for-beginners\n","- What we expect from artificial neural network is that when complexity increases, we use more hidden layers and our model can adapt better. As a result accuracy increase.\n","- **Steps of ANN:**\n","    1. Import Libraries\n","        - In order to show you, I import again but we actually imported them at previous parts.\n","    1. Prepare Dataset\n","        - Totally same with previous part(logistic regression).\n","        - We use same dataset so we only need train_loader and test_loader. \n","        - We use same batch size, epoch and iteration numbers.\n","    1. Create ANN Model\n","        - We add 3 hidden layers.\n","        - We use ReLU, Tanh and ELU activation functions for diversity.\n","    1. Instantiate Model Class\n","        - input_dim = 28*28 # size of image px*px\n","        - output_dim = 10  # labels 0,1,2,3,4,5,6,7,8,9\n","        - Hidden layer dimension is 150. I only choose it as 150 there is no reason. Actually hidden layer dimension is hyperparameter and it should be chosen and tuned. You can try different values for hidden layer dimension and observe the results.\n","        - create model\n","    1. Instantiate Loss Class\n","        - Cross entropy loss\n","        - It also has softmax(logistic function) in it.\n","    1. Instantiate Optimizer Class\n","        - SGD Optimizer\n","    1. Traning the Model\n","    1. Prediction\n","- As a result, as you can see from plot, while loss decreasing, accuracy is increasing and our model is learning(training). \n","- Thanks to hidden layers model learnt better and accuracy(almost 95%) is better than accuracy of logistic regression model."]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"6925f8ed-54b7-4d9a-9801-acd65f213bc9","_uuid":"cf25ee4b28129a47bac4c9dc7d932295155b79f7","collapsed":true,"trusted":true},"outputs":[],"source":["# Import Libraries\n","import torch\n","import torch.nn as nn\n","import torchvision.transforms as transforms\n","from torch.autograd import Variable"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"3472f1c1-5888-4abe-822c-3a493a5f8be5","_uuid":"cefd0bb2f23b80f30ca65cbb08859ad81ab12e08","collapsed":true,"trusted":true},"outputs":[],"source":["# Create ANN Model\n","class ANNModel(nn.Module):\n","    def __init__(self, input_dim, hidden_dim, output_dim):\n","        super(ANNModel, self).__init__()\n","        # Linear function 1: 784 --> 100\n","        self.fc1 = nn.Linear(input_dim, hidden_dim) \n","        # Non-linearity 1\n","        self.relu1 = nn.ReLU()\n","        \n","        # Linear function 2: 100 --> 100\n","        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n","        # Non-linearity 2\n","        self.tanh2 = nn.Tanh()\n","        \n","        # Linear function 3: 100 --> 100\n","        self.fc3 = nn.Linear(hidden_dim, hidden_dim)\n","        # Non-linearity 3\n","        self.elu3 = nn.ELU()\n","        \n","        # Linear function 4 (readout): 100 --> 10\n","        self.fc4 = nn.Linear(hidden_dim, output_dim)  \n","    \n","    def forward(self, x):\n","        # Linear function 1\n","        out = self.fc1(x)\n","        # Non-linearity 1\n","        out = self.relu1(out)\n","        \n","        # Linear function 2\n","        out = self.fc2(out)\n","        # Non-linearity 2\n","        out = self.tanh2(out)\n","        \n","        # Linear function 2\n","        out = self.fc3(out)\n","        # Non-linearity 2\n","        out = self.elu3(out)\n","        \n","        # Linear function 4 (readout)\n","        out = self.fc4(out)\n","        return out\n","\n","# instantiate ANN\n","input_dim = 28*28\n","hidden_dim = 150 #hidden layer dim is one of the hyper parameter and it should be chosen and tuned. For now I only say 150 there is no reason.\n","output_dim = 10\n","\n","# Create ANN\n","model = ANNModel(input_dim, hidden_dim, output_dim)\n","\n","# Cross Entropy Loss \n","error = nn.CrossEntropyLoss()\n","\n","# SGD Optimizer\n","learning_rate = 0.02\n","optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"7550e98b-5011-4d09-88ee-97b0ecbc6f19","_uuid":"c91694f3af94e4e1b76ab01489e186718c70ccd3","collapsed":true,"trusted":true},"outputs":[],"source":["# ANN model training\n","count = 0\n","loss_list = []\n","iteration_list = []\n","accuracy_list = []\n","for epoch in range(num_epochs):\n","    for i, (images, labels) in enumerate(train_loader):\n","\n","        train = Variable(images.view(-1, 28*28))\n","        labels = Variable(labels)\n","        \n","        # Clear gradients\n","        optimizer.zero_grad()\n","        \n","        # Forward propagation\n","        outputs = model(train)\n","        \n","        # Calculate softmax and ross entropy loss\n","        loss = error(outputs, labels)\n","        \n","        # Calculating gradients\n","        loss.backward()\n","        \n","        # Update parameters\n","        optimizer.step()\n","        \n","        count += 1\n","        \n","        if count % 50 == 0:\n","            # Calculate Accuracy         \n","            correct = 0\n","            total = 0\n","            # Predict test dataset\n","            for images, labels in test_loader:\n","\n","                test = Variable(images.view(-1, 28*28))\n","                \n","                # Forward propagation\n","                outputs = model(test)\n","                \n","                # Get predictions from the maximum value\n","                predicted = torch.max(outputs.data, 1)[1]\n","                \n","                # Total number of labels\n","                total += len(labels)\n","\n","                # Total correct predictions\n","                correct += (predicted == labels).sum()\n","            \n","            accuracy = 100 * correct / float(total)\n","            \n","            # store loss and iteration\n","            loss_list.append(loss.data)\n","            iteration_list.append(count)\n","            accuracy_list.append(accuracy)\n","            if count % 500 == 0:\n","                # Print Loss\n","                print('Iteration: {}  Loss: {}  Accuracy: {} %'.format(count, loss.data[0], accuracy))"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"5579a7d6-7766-4d0f-b9d0-584cb4f28321","_uuid":"c5e2e6da7f1ee801e38358dc28d4c99e32d2b761","collapsed":true,"trusted":true},"outputs":[],"source":["# visualization loss \n","plt.plot(iteration_list,loss_list)\n","plt.xlabel(\"Number of iteration\")\n","plt.ylabel(\"Loss\")\n","plt.title(\"ANN: Loss vs Number of iteration\")\n","plt.show()\n","\n","# visualization accuracy \n","plt.plot(iteration_list,accuracy_list,color = \"red\")\n","plt.xlabel(\"Number of iteration\")\n","plt.ylabel(\"Accuracy\")\n","plt.title(\"ANN: Accuracy vs Number of iteration\")\n","plt.show()"]},{"cell_type":"markdown","metadata":{"_cell_guid":"50bbb2e7-15d8-47f5-8f31-25e0d0cb9e29","_uuid":"cd8f261d231acaccd0f0bc8466fc28c1b0c2f567"},"source":["<a id=\"5\"></a> <br>\n","### Convolutional Neural Network (CNN)\n","- CNN is well adapted to classify images.\n","- You can learn CNN basics and concepts from Pourya's tutorial: https://www.kaggle.com/pouryaayria/convolutional-neural-networks-tutorial-tensorflow\n","- **Steps of CNN:**\n","    1. Import Libraries\n","    1. Prepare Dataset\n","        - Totally same with previous parts.\n","        - We use same dataset so we only need train_loader and test_loader. \n","    1. Convolutional layer: \n","        - Create feature maps with filters(kernels).\n","        - Padding: After applying filter, dimensions of original image decreases. However, we want to preserve as much as information about the original image. We can apply padding to increase dimension of feature map after convolutional layer.\n","        - We use 2 convolutional layer.\n","        - Number of feature map is out_channels = 16\n","        - Filter(kernel) size is 5*5\n","    1. Pooling layer: \n","        - Prepares a condensed feature map from output of convolutional layer(feature map) \n","        - 2 pooling layer that we will use max pooling.\n","        - Pooling size is 2*2\n","    1. Flattening: Flats the features map\n","    1. Fully Connected Layer: \n","        - Artificial Neural Network that we learnt at previous part.\n","        - Or it can be only linear like logistic regression but at the end there is always softmax function.\n","        - We will not use activation function in fully connected layer.\n","        - You can think that our fully connected layer is logistic regression.\n","        - We combine convolutional part and logistic regression to create our CNN model.\n","    1. Instantiate Model Class\n","        - create model\n","    1. Instantiate Loss Class\n","        - Cross entropy loss\n","        - It also has softmax(logistic function) in it.\n","    1. Instantiate Optimizer Class\n","        - SGD Optimizer\n","    1. Traning the Model\n","    1. Prediction\n","- As a result, as you can see from plot, while loss decreasing, accuracy is increasing and our model is learning(training). \n","- Thanks to convolutional layer, model learnt better and accuracy(almost 98%) is better than accuracy of ANN. Actually while tuning hyperparameters, increase in iteration and expanding convolutional neural network can increase accuracy but it takes too much running time that we do not want at kaggle.   \n","        "]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"abbc86d1-f677-4d4b-9b7b-09c7f9962288","_uuid":"c78fdf4401cb34db0d963df0249bf92144bc5fbd","collapsed":true,"trusted":true},"outputs":[],"source":["# Import Libraries\n","import torch\n","import torch.nn as nn\n","import torchvision.transforms as transforms\n","from torch.autograd import Variable"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"9ca5af9e-6821-4d60-8084-edb523a39c6b","_uuid":"4915535771ffdd33ef480200393216f215b4fc48","collapsed":true,"trusted":true},"outputs":[],"source":["# Create CNN Model\n","class CNNModel(nn.Module):\n","    def __init__(self):\n","        super(CNNModel, self).__init__()\n","        \n","        # Convolution 1\n","        self.cnn1 = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=5, stride=1, padding=0)\n","        self.relu1 = nn.ReLU()\n","        \n","        # Max pool 1\n","        self.maxpool1 = nn.MaxPool2d(kernel_size=2)\n","     \n","        # Convolution 2\n","        self.cnn2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=5, stride=1, padding=0)\n","        self.relu2 = nn.ReLU()\n","        \n","        # Max pool 2\n","        self.maxpool2 = nn.MaxPool2d(kernel_size=2)\n","        \n","        # Fully connected 1\n","        self.fc1 = nn.Linear(32 * 4 * 4, 10) \n","    \n","    def forward(self, x):\n","        # Convolution 1\n","        out = self.cnn1(x)\n","        out = self.relu1(out)\n","        \n","        # Max pool 1\n","        out = self.maxpool1(out)\n","        \n","        # Convolution 2 \n","        out = self.cnn2(out)\n","        out = self.relu2(out)\n","        \n","        # Max pool 2 \n","        out = self.maxpool2(out)\n","        out = out.view(out.size(0), -1)\n","\n","        # Linear function (readout)\n","        out = self.fc1(out)\n","        \n","        return out\n","\n","# batch_size, epoch and iteration\n","batch_size = 100\n","n_iters = 2500\n","num_epochs = n_iters / (len(features_train) / batch_size)\n","num_epochs = int(num_epochs)\n","\n","# Pytorch train and test sets\n","train = torch.utils.data.TensorDataset(featuresTrain,targetsTrain)\n","test = torch.utils.data.TensorDataset(featuresTest,targetsTest)\n","\n","# data loader\n","train_loader = torch.utils.data.DataLoader(train, batch_size = batch_size, shuffle = False)\n","test_loader = torch.utils.data.DataLoader(test, batch_size = batch_size, shuffle = False)\n","    \n","# Create ANN\n","model = CNNModel()\n","\n","# Cross Entropy Loss \n","error = nn.CrossEntropyLoss()\n","\n","# SGD Optimizer\n","learning_rate = 0.1\n","optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"99a8903c-da15-496c-96b7-f5402c8fc5f0","_uuid":"f44e02d25698ac1a014795d972a384a3f3003d35","collapsed":true,"trusted":true},"outputs":[],"source":["# CNN model training\n","count = 0\n","loss_list = []\n","iteration_list = []\n","accuracy_list = []\n","for epoch in range(num_epochs):\n","    for i, (images, labels) in enumerate(train_loader):\n","        \n","        train = Variable(images.view(100,1,28,28))\n","        labels = Variable(labels)\n","        \n","        # Clear gradients\n","        optimizer.zero_grad()\n","        \n","        # Forward propagation\n","        outputs = model(train)\n","        \n","        # Calculate softmax and ross entropy loss\n","        loss = error(outputs, labels)\n","        \n","        # Calculating gradients\n","        loss.backward()\n","        \n","        # Update parameters\n","        optimizer.step()\n","        count += 1\n","        if count % 50 == 0:\n","            # Calculate Accuracy         \n","            correct = 0\n","            total = 0\n","            # Iterate through test dataset\n","            for images, labels in test_loader:\n","                \n","                test = Variable(images.view(100,1,28,28))\n","                \n","                # Forward propagation\n","                outputs = model(test)\n","                \n","                # Get predictions from the maximum value\n","                predicted = torch.max(outputs.data, 1)[1]\n","                \n","                # Total number of labels\n","                total += len(labels)\n","                \n","                correct += (predicted == labels).sum()\n","            \n","            accuracy = 100 * correct / float(total)\n","            \n","            # store loss and iteration\n","            loss_list.append(loss.data)\n","            iteration_list.append(count)\n","            accuracy_list.append(accuracy)\n","            if count % 500 == 0:\n","                # Print Loss\n","                print('Iteration: {}  Loss: {}  Accuracy: {} %'.format(count, loss.data[0], accuracy))"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ac9e4aee-b8af-4641-8794-bad03b650179","_uuid":"44c1ed412d778f3e6b08f11bddc5321f63e408dd","collapsed":true,"trusted":true},"outputs":[],"source":["# visualization loss \n","plt.plot(iteration_list,loss_list)\n","plt.xlabel(\"Number of iteration\")\n","plt.ylabel(\"Loss\")\n","plt.title(\"CNN: Loss vs Number of iteration\")\n","plt.show()\n","\n","# visualization accuracy \n","plt.plot(iteration_list,accuracy_list,color = \"red\")\n","plt.xlabel(\"Number of iteration\")\n","plt.ylabel(\"Accuracy\")\n","plt.title(\"CNN: Accuracy vs Number of iteration\")\n","plt.show()"]},{"cell_type":"markdown","metadata":{"_cell_guid":"a508a4c8-0719-4a8f-847c-bfce1ceef30f","_uuid":"6ce8edd6d5fbf0019d6ab189f8ed1fd9cde0ac85"},"source":["### Conclusion\n","In this tutorial, we learn: \n","1. Basics of pytorch\n","1. Linear regression with pytorch\n","1. Logistic regression with pytorch\n","1. Artificial neural network with with pytorch\n","1. Convolutional neural network with pytorch\n","1. Recurrent neural network with pytorch\n","    - https://www.kaggle.com/kanncaa1/recurrent-neural-network-with-pytorch\n","\n","<br> **If you have any question or suggest, I will be happy to hear it **"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"4c40d91b-8a9c-456c-9300-a6686792c424","_uuid":"213619d278384044e3b0dd8577057413a9a7e408","collapsed":true,"trusted":true},"outputs":[],"source":[]}],"metadata":{"language_info":{"name":"python","version":"3.7.4-final","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat":4,"nbformat_minor":1}